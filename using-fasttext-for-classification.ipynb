{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/fasttext-twitter-derived-embeddings/twitter_derived_embeddings\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/wikinews300d1mvec/wiki-news-300d-1M.vec\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load Files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#sub=pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\npath = \"/kaggle/input/nlp-getting-started/\"\ntrain = pd.read_csv(f'{path}train.csv')\ntest = pd.read_csv(f'{path}test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['text'].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_space(text):\n    regex=re.compile(r'%\\S?20')\n    return regex.sub(r' ',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_location(x):\n    return ' '.join(train['location'].iloc[train.index[x]]+x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['keyword'].fillna(value=\"None\",inplace=True)\ntrain['keyword']=train['keyword'].apply(lambda x :remove_space(x))\n#train['text']=train['keyword']+'is location'+train['text']\ntrain_id=train['id']\ntrain.drop(columns=['id','keyword','location'],axis=1,inplace=True)\ntrain['target']='__label__'+''+train['target'].astype(str)\n\ntest['keyword'].fillna(value=\"None\",inplace=True)\ntest['keyword']=test['keyword'].apply(lambda x :remove_space(x))\n#test['text']=test['keyword']+'is location '+test['text']\ntest_id=test['id']\ntest.drop(columns=['keyword','location'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target']=train['target'].str.replace('1','disaster')\ntrain['target']=train['target'].str.replace('0','notadisaster')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['text']=train.text.str.encode('utf-8')\n#train['target']=train.target.str.encode('utf-8')\ntrain=train[['target','text']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.to_csv(r'train.txt', index=False, sep=' ',header=False)\ntest.to_csv(r'test.txt', index=False, sep=' ',header=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = (train.shape[0] * 7)/10\nn = int(round(n))\n\n# Split the file into 70% train and 30% test\nfft_train = train[:n] \nfft_test = train[n:] \nprint(fft_train.shape, fft_test.shape)\nfft_train.to_csv(r'fft_train.txt', index=False, sep=' ', header=False)\nfft_test.to_csv(r'fft_test.txt', index=False, sep=' ', header=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np=fft_train['text'].values\nlength=[]\nfor i in np:\n    length.append(len(i))\nfrom statistics import mean\nprint('Mean no. of words',mean(length))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import fasttext\nimport fasttext.util","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ftmodel = fasttext.train_supervised(input='/kaggle/working/train.txt',label_prefix=\"__label__\",neg=5,epoch=10,dim=300,loss='hs',word_ngrams=2,ws=4,minn=2,maxn=6,pretrainedVectors='/kaggle/input/wikinews300d1mvec/wiki-news-300d-1M.vec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef print_results(N, p, r):\n    print(\"N\\t\" + str(N))\n    print(\"P@{}\\t{:.3f}\".format(1, p))\n    print(\"R@{}\\t{:.3f}\".format(1, r))\n'''\nftmodel.test('/kaggle/working/train.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nftmodel.predict('Ohh!! #safetyfirst what an earthquake')[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ftmodel.predict('today is a good day')[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = test[['id','text']]\ntargets=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_label=ftmodel.predict(submit['text'][0])\npred_label=ftmodel.predict(submit['text'][345])\npred_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_label=ftmodel.predict(submit['text'][3125])\npred_label[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(submit)):\n    pred_label=ftmodel.predict(submit['text'][i])\n    print(pred_label)\n    pred = pred_label[0][0]\n    print(pred)\n    #if(pred == '__label__notadisaster'):\n     #     plabel = 0\n    #else:\n     #     plabel = 1\n    #targets.append(plabel)\nprint(targets)    \nlen(targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['target']=targets\n#submit=submit.drop(['text'],axis=1)\n#submit.to_csv('submission.csv')\nsubmit.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(os.path.join(path,'sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['target'] = targets\nsample_submission.head()\nlen(sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_df = pd.read_pickle('/kaggle/input/fasttext-twitter-derived-embeddings/twitter_derived_embeddings')\nembeddings_df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"         Token                                         Embeddings\n0           aa  [0.06992905, -0.6443515, 0.32829714, -0.420536...\n1         aaaa  [-0.29368854, -0.28680354, 0.082138516, -0.093...\n2  aaaaaaallll  [0.21100129, -0.24272849, -0.15285794, -0.2225...\n3     aaaaaand  [0.15002657, 0.121883154, -0.13981317, 0.04672...\n4  aaarrrgghhh  [0.23939471, -0.120745406, -0.023043174, -0.16...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Token</th>\n      <th>Embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa</td>\n      <td>[0.06992905, -0.6443515, 0.32829714, -0.420536...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>aaaa</td>\n      <td>[-0.29368854, -0.28680354, 0.082138516, -0.093...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>aaaaaaallll</td>\n      <td>[0.21100129, -0.24272849, -0.15285794, -0.2225...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>aaaaaand</td>\n      <td>[0.15002657, 0.121883154, -0.13981317, 0.04672...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>aaarrrgghhh</td>\n      <td>[0.23939471, -0.120745406, -0.023043174, -0.16...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"EMBEDDING_DIM = 300\n\nfasttext_embedding_idx = {}\nfor idx, row in embeddings_df.iterrows():\n    word = row[0]\n    embeddings = np.asarray(row[1], 'float32')\n    fasttext_embedding_idx[word] = embeddings\n\n# print only 20\nfasttext_embedding_idx['earthquake'][:20]","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"array([ 0.36360028,  0.06347924, -0.20796725, -0.1053633 , -0.4619699 ,\n       -0.5379099 , -0.24516329, -0.373171  ,  0.55195075, -0.0964388 ,\n       -0.02738901, -0.68742454,  0.04655449,  0.31652683, -0.28420547,\n        0.32772318, -0.48024014, -0.5669692 ,  0.5986041 , -0.4811064 ],\n      dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fasttext_embedding_idx['volcano'][:20]","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array([ 0.3942571 , -0.00165699,  0.21576007, -0.6281674 , -0.61796415,\n        0.5220277 , -0.10654958, -0.51835054,  0.11060573, -0.45126608,\n       -0.65426755, -0.5152729 , -0.17358208,  0.15663569, -0.18588951,\n        0.26260749, -0.5199955 , -0.48783213,  0.64488477, -0.32145846],\n      dtype=float32)"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}